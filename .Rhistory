# Fit the model
model <- lm(rent ~ size + bhk + areatype + city + furnishing, data = train_data)
# Summary of the model
summary(model)
# Step 7: Make Predictions----
predictions <- predict(model, newdata = test_data)
# Compare predictions with actual values
results <- data.frame(Actual = test_data$rent, Predicted = predictions)
head(results)
# Calculate RMSE
rmse <- sqrt(mean((results$Actual - results$Predicted)^2))
print(paste("RMSE:", rmse))
# Step 9: Visualize Predictions----
ggplot(results, aes(x=Actual, y=Predicted)) + geom_point() + geom_abline(slope=1, intercept = 0, color='red') + labs(title="Actual vs Predicted Rent Price", x="Actual Price", y="Predicted Price")
head(results)
train_data <- data1[train_index, ]
test_data <- data1[-train_index, ]
# view(train_data)
sapply(list(train_data, test_data),dim)
# Step 6: Build the Linear Regression Model----
str(data1)
# Fit the model
model <- lm(rent ~ size + bhk, data = train_data)
# Summary of the model
summary(model)
# Step 7: Make Predictions----
predictions <- predict(model, newdata = test_data)
cbind(test_data, predictions)
cbind(test_data %>% c(bhk,rent, size), predictions)
head(test_data)
test_data %>% c(bhk,rent, size)
cbind(test_data %>% select(c(bhk,rent, size)), predictions)
women
model1 <- lm(weight ~ height, data = women)
summary(model1)
residuals(model1)
?summary(model1)
women
newdata = data.frame(height = 66.5)
?predict(model1, )
newdata1 = data.frame(height = 66.5)
predict(model1, newdata = newdata1)
mtcars
model2 = lm(mpg ~ wt + hp, data = mtcars)
summary(model2)
#y = mx + c
#mpg = -3.8 * wt +  -.03 * hp + 37.22
predict(model2, newdata = data.frame(wt=2.9 , hp=120))
women
plot(x=height, y=weight, data=women)
plot(x=women$height, y=women$weight)
plot(model1)
iris
airquality
install.packages
# install packages & libraries
install.packages("rpart")
install.packages("rpart")
install.packages("rpart.plot")
# Load libraries
library(rpart)
library(rpart.plot)
# prepare & load the data
data(mtcars)
# Convert 'am' (transmission) to factor for classification
mtcars$am <- factor(mtcars$am, label = c("Automatic", "Manual"))
# View structure
str(mtcars)
set.seed(123) # for reproducibility
# 70% training and 30% testing
sample_idx <- sample(1:nrow(mtcars), 0.7 * nrow(mtcars))
train_data <- mtcars[sample_idx, ]
test_data <- mtcars[-sample_idx, ]
# 4. Train the Decision Tree Model
dt_model <- rpart(am ~., data = train_data, method = "class")
# Print Model
print(dt_model)
# Plot the tree
rpart.plot(dt_model, extra = 106) #extra = 106 shows prob and % at each mode
# Predict on test data
predictions <- predict(dt_model, test_data, type = "class")
# View predicted  values
print(predictions)
# Confusion matrix
conf_matrix <- table(Predicted = predictions, Actual = test_data$am)
# Print confusion matrix
print(conf_matrix)
# Accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Accuracy : ", round(accuracy*100, 2), %\n)
cat("Accuracy : ", round(accuracy * 100, 2), "%\n")
# 1. Load libraries
library(rpart)
library(rpart.plot)
# 2. prepare & load the data
data(mtcars)
# Convert 'am' (transmission) to factor for classification
mtcars$am <- factor(mtcars$am, label = c("Automatic", "Manual"))
# View structure
str(mtcars)
set.seed(123) # for reproducibility
# 70% training and 30% testing
sample_idx <- sample(1:nrow(mtcars), 0.7 * nrow(mtcars))
train_data <- mtcars[sample_idx, ]
test_data <- mtcars[-sample_idx, ]
sapply(list(train_data, test_data), dim)
# 4. Train the Decision Tree Model
dt_model <- rpart(am ~., data = train_data, method = "class")
# Print Model
print(dt_model)
table(train_data$am)
df1 <- train_data %>% filter(wt>=2.965)
library(dplyr)
df1 <- train_data %>% filter(wt>=2.965)
df2 <- train_data %>% filer(wt < 2.865)
df2 <- train_data %>% filter(wt < 2.865)
table(df1$am)
# Print Model
print(dt_model)
table(df2$am)
# Plot the tree
rpart.plot(dt_model, extra = 106) #extra = 106 shows prob and % at each mode
# Predict on test data
predictions <- predict(dt_model, test_data, type = "class")
# View predicted  values
print(predictions)
test_data
cbind(test_data, predictions)
cbind(test_data, predictions)
# Confusion matrix
conf_matrix <- table(Predicted = predictions, Actual = test_data$am)
# Print confusion matrix
print(conf_matrix)
cbind(test_data, predictions)
# Confusion matrix
conf_matrix <- table(Predicted = predictions, Actual = test_data$am)
# Print confusion matrix
print(conf_matrix)
# Accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Accuracy : ", round(accuracy * 100, 2), "%\n")
head(iris)
set.seed(1234)
iris.rp = rpart(Species ~., method = 'class', data = iris, control = rpart.control(minsplit=4, cp=0.0001))
print(iris.rp)
# Plot the tree
rpart.plot(iris.rp, extra = 106) #extra = 106 shows prob and % at each mode
test_data <- mtcars[-sample, idx]
train_data <- iris[sample_idx, ]
# 70% training and 30% training
sample_idx <- sample(1:nrow(iris), 0.7 * nrow(iris))
train_data <- iris[sample_idx, ]
test_data <- mtcars[-sample
-idx]
iris.rp = rpart(Species ~., method = 'class', data = iris, control = rpart.control(minsplit=4, cp=0.0001))
print(iris.rp)
# Plot the tree
rpart.plot(iris.rp, extra = 106) #extra = 106 shows prob and % at each mode
# check the data
head(iris)
# for reproducibility
set.seed(1234)
# 70% training and 30% training
sample_idx <- sample(1:nrow(iris), 0.7 * nrow(iris))
train_data <- iris[sample_idx, ]
test_data <- mtcars[-sample
-idx]
test_data <- mtcars[-sample_idx]
sapply(list(train_data, test_data),dim)
table(train_data$am)
df1 <- train_data %>% filter(Petal.Length<2.45)
table(df1$am)
dt_model <- rpart(Species ~ ., data = train_data, method = "class")
print(dt_model)
rpart.plot(dt_model, extra = 106)
prediction <- predict(dt_model,test_data, type = 'class')
prediction <- predict(dt_model,test_data, type = 'class')
rpart.plot(dt_model, extra = 106)
prediction <- predict(dt_model,test_data, type = 'class')
# View Predicted Values
print(prediction)
cbind(test_data, prediction)
prediction <- predict(dt_model,test_data, type = 'class')
rpart.plot(dt_model, extra = 104)
prediction <- predict(dt_model,test_data, type = 'class')
#iris.rp = rpart(Species ~., method = 'class', data = iris, control = rpart.control(minsplit=4, cp=0.0001))
# print(iris.rp)
test_data
# 70% training and 30% training
sample_idx <- sample(1:nrow(iris), 0.7 * nrow(iris))
train_data <- iris[sample_idx, ]
test_data <- iris[-sample_idx]
sapply(list(train_data, test_data),dim)
table(train_data$am)
df1 <- train_data %>% filter(Petal.Length<2.45)
table(df1$am)
df2 <- train_data %>% filter(Petal.Length>=2.45)
table(df2$am)
dt_model <- rpart(Species ~ ., data = train_data, method = "class")
print(dt_model)
#iris.rp = rpart(Species ~., method = 'class', data = iris, control = rpart.control(minsplit=4, cp=0.0001))
# print(iris.rp)
test_data
rpart.plot(dt_model, extra = 104)
prediction <- predict(dt_model,test_data, type = 'class')
#iris.rp = rpart(Species ~., method = 'class', data = iris, control = rpart.control(minsplit=4, cp=0.0001))
# print(iris.rp)
test_data
sapply(list(train_data, test_data), names)
test_data <- iris[-sample_idx, ]
sapply(list(train_data, test_data), names)
sapply(list(train_data, test_data),dim)
table(train_data$am)
df1 <- train_data %>% filter(Petal.Length<2.45)
table(df1$am)
df2 <- train_data %>% filter(Petal.Length>=2.45)
table(df2$am)
dt_model <- rpart(Species ~ ., data = train_data, method = "class")
print(dt_model)
#iris.rp = rpart(Species ~., method = 'class', data = iris, control = rpart.control(minsplit=4, cp=0.0001))
# print(iris.rp)
test_data
rpart.plot(dt_model, extra = 104)
prediction <- predict(dt_model,test_data, type = 'class')
# View Predicted Values
print(prediction)
cbind(test_data, prediction)
conf_matrix <- table(Predicted = prediction, Actual = test_data$am)
print(conf_matrix)
# Plot the tree
rpart.plot(iris.rp, extra = 106) #extra = 106 shows prob and % at each mode
view(iris)
library(tidyverse)
view(iris)
print(dt_model)
iris.rp = rpart(Species ~., method = 'class', data = iris, control = rpart.control(minsplit=2, cp=0.0001))
# print(iris.rp)
test_data
rpart.plot(dt_model, extra = 104)
iris.rp = rpart(Species ~., method = 'class', data = iris, control = rpart.control(minsplit=2, cp=0.000))
# print(iris.rp)
test_data
rpart.plot(dt_model, extra = 104)
prediction <- predict(dt_model,test_data, type = 'class')
# View Predicted Values
print(prediction)
cbind(test_data, prediction)
conf_matrix <- table(Predicted = prediction, Actual = test_data$am)
print(iris.rp)
# Plot the tree
rpart.plot(iris.rp, extra = 106) #extra = 106 shows prob and % at each mode
?rpart
iris.rp = rpart(Species ~., method = 'class', data = iris, control = rpart.control(minsplit=4, cp=0.0001, maxdepth = 2))
print(iris.rp)
rpart.plot(dt_model, extra = 104)
iris.rp = rpart(Species ~., method = 'class', data = iris, control = rpart.control(minsplit=4, cp=0.0001, maxdepth = 3))
print(iris.rp)
test_data
rpart.plot(dt_model, extra = 104)
prediction <- predict(dt_model,test_data, type = 'class')
# View Predicted Values
print(prediction)
rpart.plot(dt_model, extra = 104)
prediction <- predict(dt_model,test_data, type = 'class')
iris.rp = rpart(Species ~., method = 'class', data = iris, control = rpart.control(minsplit=4, cp=0.000, maxdepth = 3))
print(iris.rp)
test_data
rpart.plot(dt_model, extra = 104)
prediction <- predict(dt_model,test_data, type = 'class')
# View Predicted Values
print(prediction)
cbind(test_data, prediction)
iris.rp = rpart(Species ~., method = 'class', data = iris, control = rpart.control(minsplit=10, cp=0.005, maxdepth = 35)
iris.rp = rpart(Species ~., method = 'class', data = iris, control = rpart.control(minsplit=10, cp=0.005, maxdepth = 5)
iris.rp = rpart(Species ~., method = 'class', data = iris, control = rpart.control(minsplit=10, cp=0.005, maxdepth = 5))
print(iris.rp)
test_data
rpart.plot(dt_model, extra = 104)
prediction <- predict(dt_model,test_data, type = 'class')
# View Predicted Values
print(prediction)
print(iris.rp)
iris.rp = rpart(Species ~., method = 'class', data = iris, minbucket=round, control = rpart.control(minsplit=10, cp=0.005, maxdepth = 5))
iris.rp = rpart(Species ~., method = 'class', data = iris, min_bucket=round, control = rpart.control(minsplit=10, cp=0.005, maxdepth = 5))
iris.rp = rpart(Species ~., method = 'class', data = iris, minbucket=round, control = rpart.control(minsplit=10, cp=0.005, maxdepth = 5))
iris.rp = rpart(Species ~., method = 'class', data = iris, control = rpart.control(minsplit=10, cp=0.005, maxdepth = 5, minbucket = round))
rpart.plot(dt_model, extra = 104, cex=1.5)
printcp(iris.rp)
prediction <- predict(dt_model,test_data, type = 'class')
test_data
sample1 = data.frame(Sepal.Length=4.0, Sepal.width=3.5, Petal.Length=1.7, Petal.Width=0.3)
predict(dt_model, sample1, type = 'class')
sample1 = data.frame(Sepal.Length=4.0, Sepal.Width=3.5, Petal.Length=1.7, Petal.Width=0.3)
predict(dt_model, sample1, type = 'class')
# View Predicted Values
print(prediction)
sample1 = data.frame(Sepal.Length=4.0, Sepal.Width=3.5, Petal.Length=2.6, Petal.Width=0.3)
predict(dt_model, sample1, type = 'class')
sample1 = data.frame(Sepal.Length=4.0, Sepal.Width=3.5, Petal.Length=2.6, Petal.Width=1.6)
predict(dt_model, sample1, type = 'class')
sample1 = data.frame(Sepal.Length=4.0, Sepal.Width=3.5, Petal.Length=2.6, Petal.Width=1.76)
predict(dt_model, sample1, type = 'class')
rpart.plot(dt_model, extra = 104, cex=1.0)
# 1. Load libraries
library(rpart)
library(rpart.plot)
library(dplyr)
library(tidyverse)
# 2. prepare & load the data
data(mtcars)
# Convert 'am' (transmission) to factor for classification
mtcars$am <- factor(mtcars$am, label = c("Automatic", "Manual"))
# View structure
str(mtcars)
set.seed(123) # for reproducibility
# 70% training and 30% testing
sample_idx <- sample(1:nrow(mtcars), 0.7 * nrow(mtcars))
train_data <- mtcars[sample_idx, ]
test_data <- mtcars[-sample_idx, ]
sapply(list(train_data, test_data), dim)
table(train_data$am)
df1 <- train_data %>% filter(wt>=2.965)
table(df1$am)
df2 <- train_data %>% filter(wt < 2.865)
table(df2$am)
# 4. Train the Decision Tree Model
dt_model <- rpart(am ~., data = train_data, method = "class")
# Print Model
print(dt_model)
# Plot the tree
rpart.plot(dt_model, extra = 106) #extra = 106 shows prob and % at each mode
# Predict on test data
predictions <- predict(dt_model, test_data, type = "class")
# View predicted  values
print(predictions)
test_data
cbind(test_data, predictions)
# Confusion matrix
conf_matrix <- table(Predicted = predictions, Actual = test_data$am)
# Print confusion matrix
print(conf_matrix)
# Accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Accuracy : ", round(accuracy * 100, 2), "%\n")
# check the data
head(iris)
# for reproducibility
set.seed(1234)
# 70% training and 30% testing
sample_idx <- sample(1:nrow(iris), 0.7 * nrow(iris))
train_data <- iris[sample_idx, ]
test_data <- iris[-sample_idx, ]
sapply(list(train_data, test_data), names)
sapply(list(train_data, test_data),dim)
table(train_data$am)
df1 <- train_data %>% filter(Petal.Length<2.45)
table(df1$am)
df2 <- train_data %>% filter(Petal.Length>=2.45)
table(df2$am)
dt_model <- rpart(Species ~ ., data = train_data, method = "class")
print(dt_model)
iris.rp = rpart(Species ~., method = 'class', data = iris, control = rpart.control(minsplit=10, cp=0.005, maxdepth = 5, minbucket = round))
dt_model <- rpart(Species ~ ., data = train_data, method = "class")
print(dt_model)
rpart.plot(dt_model)
printcp(dt_model)
# 70% training and 30% testing
sample_idx <- sample(1:nrow(iris), 0.7 * nrow(iris))
train_data <- iris[sample_idx, ]
test_data <- iris[-sample_idx, ]
test_data <- iris[-sample_idx, ]
sapply(list(train_data, test_data), names)
dt_model <- rpart(Species ~ ., data = train_data, method = "class")
print(dt_model)
rpart.plot(dt_model)
printcp(dt_model)
print(dt_model)
summary(dt_model)
rpart.plot(dt_model, nn=T)
train_data %>% filter(petal.Length < 2.5) %>% tally()
train_data %>% filter(Petal.Length < 2.5) %>% tally()
31/105
train_data %>% filter(!Petal.Length < 2.5) %>% tally()
74/105
train_data %>% filter(Petal.Length < 2.5) %>% filter(Petal.Width < 1.8) %>% tally()
31/105
train_data %>% filter(Petal.Length < 2.5) %>% filter(Petal.Width < 1.75) %>% tally()
train_data %>% filter(!Petal.Length < 2.5) %>% filter(Petal.Width < 1.75) %>% tally()
31/105
39/105
# 1. Load libraries
library(rpart)
library(rpart.plot)
library(dplyr)
library(tidyverse)
set.seed (123)
sales <- data.frame(
date = as.Date('2024-01-01') + 0:29,
store = sample(c("StoreA", "StoreB"), 30, replace = TRUE),
product = sample(c('Laptop', 'Tablet', 'Phone'), 30, replace = T),
units_sold = sample(5:50, 30, replace = T),
price = sample(300:1000, 30, replace = T)
)
# Add revenue column
sales$Revenue <- sales$units_sold * sales$price
# View first few rows
head(sales)
# Add revenue column
sales$revenue <- sales$units_sold * sales$price
# View first few rows
head(sales)
set.seed (123)
sales <- data.frame(
date = as.Date('2024-01-01') + 0:29,
store = sample(c("StoreA", "StoreB"), 30, replace = TRUE),
product = sample(c('Laptop', 'Tablet', 'Phone'), 30, replace = T),
units_sold = sample(5:50, 30, replace = T),
price = sample(300:1000, 30, replace = T)
)
# Add revenue column
sales$revenue <- sales$units_sold * sales$price
# View first few rows
head(sales)
# Compute Descriptive Stats (Mean, Median, etc.)
summary(sales$revenue)
mean(sales$revenue)
median(sales$revenue)
sd(sales$revenue)
# Visualize Data
library(ggplot2)
sales %>% ggplot(., aes(x = Revenue)) + geom_histogram(binwidth = 500, fill = "steelblue", color = 'black') + labs(title = "Revenue Distribution")
library(dplyr)
library(tidyverse)
# Visualize Data
library(ggplot2)
sales %>% ggplot(., aes(x = Revenue)) + geom_histogram(binwidth = 500, fill = "steelblue", color = 'black') + labs(title = "Revenue Distribution")
sales %>% ggplot(., aes(x = revenue)) + geom_histogram(binwidth = 500, fill = "steelblue", color = 'black') + labs(title = "Revenue Distribution")
sales %>% ggplot(., aes(x = revenue)) + geom_histogram(binwidth = 500, fill = "red", color = 'black') + labs(title = "Revenue Distribution")
sales %>% ggplot(., aes(x = revenue)) + geom_histogram(binwidth = 500, fill = "red", color = 'black') + labs(title = "Revenue Distribution") + geom_text(aes(title = revenue))
sales %>% ggplot(., aes(x = revenue)) + geom_histogram(binwidth = 500, fill = "red", color = 'black') + labs(title = "Revenue Distribution") + geom_text(aes(label = revenue))
sales %>% ggplot(., aes(x = revenue)) + geom_histogram(binwidth = 500, fill = "red", color = 'black') + labs(title = "Revenue Distribution") + geom_text(aes(label = revenue, y=revenue))
sales %>% ggplot(., aes(x = revenue)) + geom_histogram(binwidth = 500, fill = "red", color = 'black') + labs(title = "Revenue Distribution") + geom_text(aes(y=revenue))
sales %>% ggplot(., aes(x = revenue)) + geom_histogram(binwidth = 500, fill = "red", color = 'black') + labs(title = "Revenue Distribution")
# 1. Load libraries
library(rpart)
library(rpart.plot)
library(dplyr)
library(tidyverse)
set.seed (123)
sales <- data.frame(
date = as.Date('2024-01-01') + 0:29,
store = sample(c("StoreA", "StoreB"), 30, replace = TRUE),
product = sample(c('Laptop', 'Tablet', 'Phone'), 30, replace = T),
units_sold = sample(5:50, 30, replace = T),
price = sample(300:1000, 30, replace = T)
)
# Add revenue column
sales$revenue <- sales$units_sold * sales$price
# View first few rows
head(sales)
# Compute Descriptive Stats (Mean, Median, etc.)
summary(sales$revenue)
mean(sales$revenue)
median(sales$revenue)
sd(sales$revenue)
# Visualize Data
library(ggplot2)
sales %>% ggplot(., aes(x = revenue)) + geom_histogram(binwidth = 500, fill = "red", color = 'black') + labs(title = "Revenue Distribution")
sales %>% ggplot(., aes(x = revenue)) + geom_histogram(binwidth = 800, fill = "red", color = 'black') + labs(title = "Revenue Distribution")
sales %>% ggplot(., aes(x = factor(date), y = revenue)) + geom_histogram(binwidth = 800, fill = "red", color = 'black') + labs(title = "Revenue Distribution")
sales %>% ggplot(., aes(y = revenue)) + geom_histogram(binwidth = 800, fill = "red", color = 'black') + labs(title = "Revenue Distribution")
sales %>% ggplot(., aes(x=factor(date), y=revenue, fill = product)) + geom_bar(stat = 'identity')
# Build linear model
model <- lm(revenue ~ units_sold + price, data = sales)
# Summary of model
summary(model)
# Build linear model
model <- lm(revenue ~ units_sold * price, data = sales)
# Summary of model
summary(model)
# Build linear model
model <- lm(revenue ~ units_sold * price, data = sales)
# Summary of model
summary(model)
# Build linear model
model <- lm(revenue ~ units_sold + price, data = sales)
# Summary of model
summary(model)
new_data <- data.frame(units_sold = c(20, 35), price = c(600, 750))
predict(model, newdata = new_data)
# Evaluate the Model :
predicted <- predict(model, sales)
actual <- sales$revenue
# Root Mean Squared Error (RMSE)
rmse <- sqrt(mean((predicted - actual)^2))
rmse
(sqrt(mean((actual)^2)))
(sqrt(mean((actual)^2)) *10)/ 100)
(sqrt(mean((actual)^2)) *10/ 100)
1 Create dataset	data.frame()
# 1 Create dataset	data.frame()
# 2	Descriptive stats	summary(), mean()
# 3	Visualization	ggplot2::ggplot()
# 4	Model revenue prediction	lm()
# 5	Evaluate prediction error	predict(), rmse
# 1 Create dataset	data.frame()
# 2	Descriptive stats	summary(), mean()
# 3	Visualization	ggplot2::ggplot()
# 4	Model revenue prediction	lm()
# 5	Evaluate prediction error	predict(), rmse
(sqrt(mean((actual)^2)) *10/ 100)
head(sales)

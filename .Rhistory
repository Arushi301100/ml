#Categorical Data
#Creating Nominal Data----
nominal = sample(c('Male', 'Female'), size = 25, replace = T, prob = c(0.6, 0.4))
nominal
table(nominal)
prop.table(table(nominal))
#Creating Ordinal Data of Zomato Ratings----
grades = sample(c('A', 'B', 'C'), size = 25, replace = T, prob = c(0.45, 0.35, 0.2))
table(grades)
prop.table(table(grades))
sort(grades)
?factor
grades1 = factor(grades, ordered = T, levels = c('C', 'B', 'A'))
grades1
sort(grades1)
sort(grades)
grades1 = factor(grades, ordered = T, levels = c('B', 'C', 'A'))
sort(grades1)
#Creating Ordinal Data of Zomato Ratings----
grades = sample(c('A', 'B', 'C', 'D'), size = 25, replace = T, prob = c(0.45, 0.3, 0.15, 0.1))
table(grades)
prop.table(table(grades))
grades1 = factor(grades, ordered = T, levels = c('C', 'B', 'A', 'D'))
grades1
sort(grades1)
length(grades1)
sort(grades1)
sort(grades1)[length(grades1)/2]
sort(grades1)[12]
sort(grades1)[c(12, 13)]
#Creating Continuos data or Ratio scale of Students Marks----
salary = rnorm(25, mean = 70, sd = 4)
salary
#Creating Continuos data or Ratio scale of Students Marks----
marks = round(rnorm(25, mean = 70, sd = 4))
marks
#Creating Discrete data of student ranks----
rank = sample(1:25, size = 25, replace = F)
rank
#mean
(meanrank = mean(rank))
(meanmrks = mean(marks))
(meanmarks = mean(marks))
sort(grades1)
# Median
(med_grades = median(sort(grades1)))
# Median
med_grades = median(sort(grades1))
# Median
grades1= sort(grades1)
med_grades = median(sort(grades1))
med_grades = median(grades1)
med_grades = mode(grades1)
med_grades
# Mode
grades1= sort(grades1)
mode_grades = mode(grades1)
mode_grades
# Median
med_rank = median(rank)
med_rank
med_marks = median(marks)
# Median
(med_rank = median(rank))
(med_marks = median(marks))
marks
table(marks)
sort(table(marks))
grade_table = table(grades1)
# Find mode
mode_grade <- names(grade_table)[which.max(grade_table)]
mode_grade
(grade_table = table(grades1))
sd(marks)
range(marks)
min(marks)
max(marks)
quantile(marks)
rank
?runif
# Create Data Frame manually----
c_code <- c('AUCG', 'AUCG', 'AUMP', 'AUMP', 'AUMH', 'AUUP')
dept <- c('Computer Science', 'Management', 'Law', 'Engineering', 'Pharmacy', 'Education')
faculty_count <- c(30, 20, 18, 50, 15, 10)
std_count <- c(600, 400, 350, 1200, 200, 150)
avg_tlr_score <- c(78.5, 74.3, 81.2, 76.7, 80.5, 72.1)
# Dataframe
(univ_data <- data.frame(c_code, dept, faculty_count, std_count, avg_tlr_score))
#Load libraries
library(psych)
install.packages("pastecs")
#Load libraries
library(psych)
install.packages("psych")
#Load libraries
library(psych)
library(pastecs)
library(doBy)
#Basic descriptive statistics
summary(univ_data)
#Basic descriptive statistics
summary(univ_data)
#Basic descriptive statistics
summary(univ_data)
#Apply functions using sapply(), across columns
sapply(univ_data[., c('faculty_count', 'std_count', 'avg_tlr_score')], mean)
#Apply functions using sapply(), across columns
sapply(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')], mean)
sapply(univ_data, [c('faculty_count', 'std_count', 'avg_tlr_score')], sd)
sapply(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')], sd)
# 1. Basic descriptive statistics
summary(univ_data)
# 2. Apply functions using sapply(), across columns
sapply(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')], mean)
sapply(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')], sd)
# 3.Detailed descriptive stats using stat.desc()
stats.desc(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')])
# 3.Detailed descriptive stats using stat.desc()
stat.desc(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')])
install.packages("pastecs")
# 3.Detailed descriptive stats using stat.desc()
stat.desc(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')])
# 4. describe() for descriptive stats (from psych package)
describe(univ_data[,c('faculty_count', 'student', 'avg_tlr_score')])
#Load libraries
library(psych)
library(pastecs)
library(doBy)
# 1. Basic descriptive statistics
summary(univ_data)
# 2. Apply functions using sapply(), across columns
sapply(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')], mean)
#Finds mean of each numeric column
sapply(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')], sd)
# 3.Detailed descriptive stats using stat.desc()
stat.desc(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')])
# 4. describe() for descriptive stats (from psych package)
describe(univ_data[,c('faculty_count', 'student', 'avg_tlr_score')])
# 4. describe() for descriptive stats (from psych package)
describe(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')])
# 5. aggregate : mean of student counts grouped by campus
aggregate(std_count ~ c_code, data = univ_data, FUN = mean)
# 6. Coefficient of variation (CV) manually:
cv_std_count <- (sd(univ_data$std_count)/mean(univ_data$std_count))
# 7. Group wise summary using summaryBy()
summaryBy(std_count + faculty_count + avg_tlr_score ~ Dept, data = univ_data, FUN=c(mean, sd))
# 8. describeBy() for descriptive stats campus-wise
describeBy(univ_data$avg_tlr_score, group = univ_data$c_code)
# Create Data Frame manually----
c_code <- c('AUCG', 'AUCG', 'AUMP', 'AUMP', 'AUMH', 'AUUP')
dept <- c('Computer Science', 'Management', 'Law', 'Engineering', 'Pharmacy', 'Education')
faculty_count <- c(30, 20, 18, 50, 15, 10)
std_count <- c(600, 400, 350, 1200, 200, 150)
avg_tlr_score <- c(78.5, 74.3, 81.2, 76.7, 80.5, 72.1)
# Dataframe
(univ_data <- data.frame(c_code, dept, faculty_count, std_count, avg_tlr_score))
#Load libraries
library(psych)
library(pastecs)
library(doBy)
# 1. Basic descriptive statistics
summary(univ_data)
str(univ_data)
# 2. Apply functions using sapply(), across columns
sapply(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')], mean)
# 1. Basic descriptive statistics
summary(univ_data)
#Finds mean of each numeric column
sapply(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')], c(sd, mean))
#Finds mean of each numeric column
sapply(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')], FUN = c(sd, mean))
#Finds mean of each numeric column
sapply(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')], FUN = (sd, mean))
list
#finds standard deviation of each numeric column
?sapply(list, function)
#Finds mean of each numeric column
#sapply(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')], FUN = (sd, mean))
#finds standard deviation of each numeric column
?sapply()
#Finds mean of each numeric column
sapply(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')], FUN = sd)
#Finds mean of each numeric column
lapply(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')], FUN = sd)
#Finds mean of each numeric column
vapply(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')], FUN = sd)
sapply(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')], FUN = function(x) c(sum =sum(x)))
sapply(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')], FUN = function(x) c(sum =sum(x), mean = mean(x), sd = sd(x)))
#includes variance, coefficient of variation, skewness, kurtosis, etc.
?stat.desc
# 3.Detailed descriptive stats using stat.desc()
pastecs::stat.desc(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')])
plot(mtcars$wt, mtcars$mpg)
cov(mtcars$wt, mtcars$mpg)
cor(mtcars$wt, mtcars$mpg)
sqrt(208)
cor(mtcars)
round(cor(mtcars), 2)
plot(mtcars$wt, mtcars$hp)
round(cor(mtcars[, c(wt, mpg, hp)]), 2)
round(cor(mtcars[, c('wt', 'mpg', 'hp')]), 2)
# 4. describe() for descriptive stats (from psych package)
psych::describe(univ_data[, c('faculty_count', 'std_count', 'avg_tlr_score')])
mtcars
model = lm(mpg ~ wt, data = mtcars)
summary(model)
?abline
plot(mtcars$wt, mtcars$mpg)
abline(mtcars$wt, mtcars$mpg)
plot(mtcars$wt, mtcars$mpg)
abline(model)
?predict
predict(model, newdata = data.frame(wt=2.5))
#library----
pacman::p_load(tidyverse, googlesheets4, patchwork)
#Data----
gsid = "1FIB4VOf-8HzHsHo9OZkbniTnIK5Pm9_lcSHDH4Dkzl4"
sheet_names(ss=gsid)
write_sheet(df17b, ss=gsid, sheet='df17')
#Data----
gsid = "1FIB4VOf-8HzHsHo9OZkbniTnIK5Pm9_lcSHDH4Dkzl4"
sheet_names(ss=gsid)
df17 = read_sheet(ss=gsid, sheet = 17, skip = 10)
head(df17)
names(df17)
cn17 = c("Y2025", "Y2024", "institution", 'country', "acad_score", "acad_rank", "emp_score", "emp_rank", "cit_score", "cit_rank", "hi_score", "hi_rank", "irn_score", "irn_rank", "score")
names(df17) = cn17
head(df17)
str(df17)
#data cleaning----
df17$Y2025
df17b <- df17 %>% mutate(Y2025 = str_replace_all(Y2025, '\\+|\\=', ''),Y2024 = str_replace_all(Y2024, '\\+|\\=', ''), acad_rank = str_replace_all(acad_rank, '\\+|\\=', ''), emp_rank = str_replace_all(emp_rank, '\\+|\\=', ''), cit_rank = str_replace_all(cit_rank, '\\+|\\=', ''), hi_rank = str_replace_all(hi_rank, '\\+|\\=', ''), irn_rank = str_replace_all(irn_rank, '\\+|\\=', '')) %>% separate_wider_delim(cols = Y2025, delim = '-', names=c('Y2025L', 'Y2025R'), too_few = "align_start", too_many = "drop", cols_remove = FALSE)  %>% separate_wider_delim(cols = Y2024, delim = '-', names=c('Y2024L', 'Y2024R'), too_few = "align_start", too_many = "drop", cols_remove = FALSE) %>% mutate(Y2025R = if_else(is.na(Y2025R), Y2025L, Y2025R), Y2024R = if_else(is.na(Y2024R), Y2024L, Y2024R)) %>% mutate_at(vars(Y2024L, Y2024R, Y2025L, Y2025R), as.integer) %>% mutate(rank_25 = round((Y2025L + Y2025R)/2), rank_24 = round((Y2024L + Y2024R)/2)) %>% select(-c(Y2025, Y2024, Y2025L, Y2025R, Y2024L, Y2024R))
str(df17b)
head(df17b)
write_sheet(df17b, ss=gsid, sheet='df17')
str(df17b)
df17b[., c(acad_score)]
df17b[, c(acad_score)]
df17b[, c('acad_score')]
names(df17b)
df17b[, c("acad_score","emp_score", "cit_score",    "hi_score",    "irn_score")]
cor(df17b[, c("acad_score","emp_score", "cit_score",    "hi_score",    "irn_score")])
round(cor(df17b[, c("acad_score","emp_score", "cit_score",    "hi_score",    "irn_score")]), 2)
install.packages("GGally")
ggpairs(df17b)
library(GGally)
ggpairs(df17b)
df17c = data.frame( df17b[, c("acad_score","emp_score", "cit_score",    "hi_score",    "irn_score")])
head(df17c)
ggpairs(df17c)
ggpairs(mtcars)
ggpairs(mtcars[c('mpg', 'wt', 'disp')])
ggpairs(mtcars[c('mpg', 'wt', 'disp', 'hp')])
install.packages("corgram")
#Creating Pair plot----
library(corgram)
#Creating Pair plot----
library(corrgram)
install.packages("corrgram")
#Creating Pair plot----
library(corrgram)
corrgram(mtcars[c('mpg', 'wt', 'disp', 'hp')])
ggcorr(mtcars[c('mpg', 'wt', 'disp', 'hp')])
#Best One
library(corrplot)
library(RColorBrewer)
M <-cor(mtcars)
corrplot(M, type="upper", order="hclust",
col=brewer.pal(n=8, name="RdYlBu"))
#library----
pacman::p_load(tidyverse, googlesheets4, patchwork)
#Data----
gsid = "1FIB4VOf-8HzHsHo9OZkbniTnIK5Pm9_lcSHDH4Dkzl4"
sheet_names(ss=gsid)
df17 = read_sheet(ss=gsid, sheet = 17, skip = 10)
head(df17)
names(df17)
cn17 = c("Y2025", "Y2024", "institution", 'country', "acad_score", "acad_rank", "emp_score", "emp_rank", "cit_score", "cit_rank", "hi_score", "hi_rank", "irn_score", "irn_rank", "score")
names(df17) = cn17
head(df17)
str(df17)
#data cleaning----
df17$Y2025
df17b <- df17 %>% mutate(Y2025 = str_replace_all(Y2025, '\\+|\\=', ''),Y2024 = str_replace_all(Y2024, '\\+|\\=', ''), acad_rank = str_replace_all(acad_rank, '\\+|\\=', ''), emp_rank = str_replace_all(emp_rank, '\\+|\\=', ''), cit_rank = str_replace_all(cit_rank, '\\+|\\=', ''), hi_rank = str_replace_all(hi_rank, '\\+|\\=', ''), irn_rank = str_replace_all(irn_rank, '\\+|\\=', '')) %>% separate_wider_delim(cols = Y2025, delim = '-', names=c('Y2025L', 'Y2025R'), too_few = "align_start", too_many = "drop", cols_remove = FALSE)  %>% separate_wider_delim(cols = Y2024, delim = '-', names=c('Y2024L', 'Y2024R'), too_few = "align_start", too_many = "drop", cols_remove = FALSE) %>% mutate(Y2025R = if_else(is.na(Y2025R), Y2025L, Y2025R), Y2024R = if_else(is.na(Y2024R), Y2024L, Y2024R)) %>% mutate_at(vars(Y2024L, Y2024R, Y2025L, Y2025R), as.integer) %>% mutate(rank_25 = round((Y2025L + Y2025R)/2), rank_24 = round((Y2024L + Y2024R)/2)) %>% select(-c(Y2025, Y2024, Y2025L, Y2025R, Y2024L, Y2024R))
str(df17b)
head(df17b)
names(df17b)
round(cor(df17b[, c("acad_score","emp_score", "cit_score",    "hi_score",    "irn_score")]), 2)
#Writing or Storing the Dataframe into a new Goggle sheet----
write_sheet(df17b, ss=gsid, sheet='df17')
#Creating Pair plot----
library(corrgram)
library(GGally)
#Creating new dataframe
df17c = data.frame( df17b[, c("acad_score","emp_score", "cit_score",    "hi_score",    "irn_score")])
head(df17c)
ggpairs(df17c)
ggpairs(mtcars[c('mpg', 'wt', 'disp', 'hp')])
corrgram(mtcars[c('mpg', 'wt', 'disp', 'hp')])
ggcorr(mtcars[c('mpg', 'wt', 'disp', 'hp')])
#Best One
library(corrplot)
library(RColorBrewer)
M <-cor(mtcars)
corrplot(M, type="upper", order="hclust",
col=brewer.pal(n=8, name="RdYlBu"))
#Writing or Storing the Dataframe into a new Goggle sheet----
write_sheet(df17b, ss=gsid, sheet='df17')
#library----
pacman::p_load(tidyverse, googlesheets4, patchwork)
#Data----
gsid = "1FIB4VOf-8HzHsHo9OZkbniTnIK5Pm9_lcSHDH4Dkzl4"
sheet_names(ss=gsid)
